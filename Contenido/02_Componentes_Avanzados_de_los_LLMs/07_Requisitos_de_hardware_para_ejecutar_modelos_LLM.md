# Requisitos de hardware para ejecutar modelos LLM en tu computadora

## Resumen

Â¿Te gustarÃ­a ejecutar modelos LLM (Large Language Models) directamente desde tu computadora personal? Antes de iniciar debes dominar algunos conceptos importantes como CPU, GPU, RAM, VRAM y cuantizaciÃ³n.

## Â¿CuÃ¡l es la diferencia entre CPU y GPU?

La CPU es un procesador general encargado de mÃºltiples tareas en la computadora. Por otro lado, la GPU estÃ¡ especializada en operaciones matemÃ¡ticas especÃ­ficas como "m por x mÃ¡s b", esenciales en tareas como los modelos LLM.

## Â¿Por quÃ© son importantes la RAM y la VRAM?

## Â¿QuÃ© funciÃ³n tiene la memoria RAM?

La **memoria RAM** almacena temporalmente archivos e informaciÃ³n activa, como cuando editas una imagen en Photoshop o navegas por mÃºltiples pestaÃ±as en Internet. Para ejecutar modelos LLM localmente, se recomienda:

* Un mÃ­nimo de 16 GB.
* Preferentemente hasta 64 GB de RAM para un rendimiento Ã³ptimo.

## Â¿CuÃ¡l es el papel de la memoria VRAM?

La VRAM (Video Random Access Memory) estÃ¡ directamente integrada con la GPU. Al estar fÃ­sicamente cercana, permite una menor latencia y mayor rendimiento. Para ejecutar modelos LLM pequeÃ±os o cuantizados, lo ideal es contar con entre 12 y 16 GB de VRAM. Las tarjetas grÃ¡ficas de consumo alcanzan hasta 36 GB en su gama mÃ¡s alta.

## Â¿QuÃ© es y quÃ© beneficios ofrece la cuantizaciÃ³n de modelos?

La cuantizaciÃ³n permite reducir el peso de los modelos de machine learning, bajando la precisiÃ³n numÃ©rica empleada. Los modelos originalmente entrenados con 16 bits pueden cuantizarse a 8 o 4 bits, disminuyendo su tamaÃ±o significativamente. Por ejemplo:

* Un modelo de 100 GB (16 bits) podrÃ­a reducirse a 25 GB (4 bits).

Estas reducciones facilitan ejecutar modelos grandes en hardware mÃ¡s modesto y accesible.

Ahora que entiendes estos conceptos, en prÃ³ximas sesiones podrÃ¡s verificar quÃ© modelos son compatibles con tu equipo utilizando herramientas como Hugging Face y Olama.

```Markdown
ğŸ§  **Ejecutar Modelos LLM en tu PC**
**Conceptos clave que debes dominar**

ğŸ” **CPU vs. GPU**
ğŸ”¹ **CPU (Procesador Central)**
Realiza tareas generales del sistema.
Encargado de mÃºltiples tareas.

ğŸ”¹ **GPU (Procesador GrÃ¡fico)**
Especializada en cÃ¡lculos matemÃ¡ticos especÃ­ficos (y= mx+b).
Esencial para tareas de machine learning y modelos LLM.

ğŸ’¾ **RAM y VRAM**
ğŸ”¸ **RAM (Memoria de Acceso Aleatorio)**
* Almacena temporalmente lo que estÃ¡s usando.
* Ejemplos: editar imÃ¡genes, tener muchas pestaÃ±as abiertas.

**Recomendado para LLM:**
âœ… MÃ­nimo: 16 GB
âœ… Ideal: hasta 64 GB

ğŸ”¸ **VRAM (Memoria de Video)**
Integrada con la GPU.
Velocidad alta gracias a su cercanÃ­a fÃ­sica con el procesador grÃ¡fico.

**Recomendado para LLM:**
âœ… De 12 a 16 GB para modelos pequeÃ±os o cuantizados
ğŸ” Hasta 36 GB en tarjetas grÃ¡ficas de gama alta a nivel personal

âš–ï¸ **Â¿QuÃ© es la CuantizaciÃ³n?**
ğŸ”½ **ReducciÃ³n de tamaÃ±o del modelo**
* Baja la precisiÃ³n numÃ©rica: de 16 bits a 8 o 4 bits.
* Menor tamaÃ±o, mismo propÃ³sito.

ğŸ“‰ **Ejemplo:** Modelo de 100 GB (16 bits) â†’ 25 GB (4 bits)
âœ… Permite ejecutar modelos grandes en computadoras modestas.
```

[REGRESAR](../02_Componentes_Avanzados_de_los_LLMs/Intro.md)